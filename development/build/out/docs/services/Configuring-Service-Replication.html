<hr>
<h2>
<a id="layout-defaulttitle-cas---configuring-service-replicationcategory-services" class="anchor" href="#layout-defaulttitle-cas---configuring-service-replicationcategory-services" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>layout: default<br>
title: CAS - Configuring Service Replication<br>
category: Services</h2>
<p>{% include variables.html %}</p>
<h1>
<a id="configure-service-replication" class="anchor" href="#configure-service-replication" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Configure Service Replication</h1>
<p>In the event that CAS service definitions are not managed globally via a <a href="Service-Management.html">centralized store</a>,<br>
definitions need to be kept in sync throughout all CAS nodes in a cluster when more than one node is deployed.<br>
When the management strategy of such definitions is to store them on disk local to<br>
each node (such as <a href="JSON-Service-Management.html">JSON</a> or <a href="YAML-Service-Management.html">YAML</a>) files,<br>
the following mechanisms may be used to copy files from one host to another.</p>
<h2>
<a id="native" class="anchor" href="#native" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Native</h2>
<p>A background task can be scheduled with the likes of <code>rsync</code> to copy files from from host to another.<br>
The job needs to of course run periodically to ensure configuration is kept in sync.<br>
This is the simplest option as CAS is completely ignorant of extra process in the background.</p>
<p>On Linux machines, <code>rsync</code> may be installed as:</p>
<pre lang="bash"><code># yum install rsync (On Red Hat based systems)
# apt-get install rsync (On Debian based systems)
</code></pre>
<p>As an example, this command will sync a directory <code>/etc/cas/services</code> from a local machine to a remote server:</p>
<pre lang="bash"><code>rsync -avz /etc/cas/services root@192.168.0.101:/etc/cas/services
</code></pre>
<p>The exact opposite of the above command may be carried as such:</p>
<pre lang="bash"><code>rsync -avzh root@192.168.0.100:/etc/cas/services /etc/cas/services
</code></pre>
<ul>
<li>To execute the transfer operation over ssh, use the <code>ssh --progress</code> flags.</li>
<li>To test the command execution in mock mode, use the <code>--dry-run</code> flag.</li>
</ul>
<h2>
<a id="hazelcast" class="anchor" href="#hazelcast" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Hazelcast</h2>
<p>If you'd rather not resort to outside tooling and processes or if the native options for your<br>
deployment are not that attractive, you can take advantage of CAS' own tooling that provides a<br>
distributed cache via Hazelcast to broadcast service definition files across the cluster and add/remove/update<br>
each node as needed. As service definitions are loaded by CAS, events are broadcasted to all<br>
CAS nodes in the cluster to pick up the changes and keep definitions in sync.</p>
<p>Support is enabled by including the following dependency in the overlay:</p>
<p>{% include casmodule.html group="org.apereo.cas" module="cas-server-support-service-registry-stream-hazelcast" %}</p>
<p>To see the relevant list of CAS properties, please <a href="../configuration/Configuration-Properties.html#service-registry-replication-hazelcast">review this guide</a>.</p>
<h2>
<a id="apache-kafka" class="anchor" href="#apache-kafka" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Apache Kafka</h2>
<p>If you'd rather not resort to outside tooling and processes or if the native options for your<br>
deployment are not that attractive, you can take advantage of CAS' own tooling that provides a<br>
distributed cache via Apache Kafka to broadcast service definition files across the cluster and add/remove/update<br>
each node as needed. As service definitions are loaded by CAS, events are broadcasted to all<br>
CAS nodes in the cluster to pick up the changes and keep definitions in sync.</p>
<p>Support is enabled by including the following dependency in the overlay:</p>
<p>{% include casmodule.html group="org.apereo.cas" module="cas-server-support-service-registry-stream-kafka" %}</p>
<p>To see the relevant list of CAS properties, please <a href="../configuration/Configuration-Properties.html#service-registry-replication-kafka">review this guide</a>.</p>
<h2>
<a id="replication-modes" class="anchor" href="#replication-modes" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Replication Modes</h2>
<p>When CAS is configured to replicate service definitions in an active-active mode, you will need to make sure the service registry scheduler is carefully tuned in order to avoid surprises and overwrites. Likewise, the same sort of check needs to be done and verified for ad-hoc dynamic changes to the CAS service registry directory, if CAS is set to monitor for changes. Delays in replication and schedule may force one node to overwrite changes to the other.</p>
<p>For instance, consider the following scenario: there are two nodes in a CAS cluster where CAS1 is set to monitor changes from <code>/etc/cas/services</code> on node N1 and CAS2 is monitoring <code>/etc/cas/services</code> directory on node N2. Both N1 and N2 on startup attempt to bootstrap each other's copies of service definitions to make sure all is synchronized correctly.</p>
<p>Now let's consider that a file is <code>/etc/cas/services/App-100.json</code> is deleted from N2. In the time that it takes from N2 to broadcast the change to N1, it is likely that service registry scheduler for N2 also wakes up and attempts to restore the state of the world by synchronizing its copies of its service definition files from the distributed cache, which means that N2 will grab a copy of the deleted service from N1 and will restore the deleted file back. This situation typically manifests itself when the service registry scheduler is set to very aggressive timeouts and can mostly be avoided by relaxing the reload operation to run on a long scheduler such as every 2 hours. Alternatively, you may decide to run an active-passive setup to only have one master node produce and broadcast changes and other slave/passive nodes simply and only consume changes when needed.</p>