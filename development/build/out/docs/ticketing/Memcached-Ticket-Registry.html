<hr>
<h2>
<a id="layout-defaulttitle-cas---memcached-ticket-registrycategory-ticketing" class="anchor" href="#layout-defaulttitle-cas---memcached-ticket-registrycategory-ticketing" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>layout: default<br>
title: CAS - Memcached Ticket Registry<br>
category: Ticketing</h2>
<p>{% include variables.html %}</p>
<h1>
<a id="memcached-ticket-registry" class="anchor" href="#memcached-ticket-registry" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Memcached Ticket Registry</h1>
<p>Memcached integration is enabled by including the following dependency in the WAR overlay:</p>
<p>{% include casmodule.html group="org.apereo.cas" module="cas-server-support-memcached-ticket-registry" %}</p>
<p>This registry stores tickets in one or more <a href="http://memcached.org/">memcached</a> instances.<br>
Memcached stores data in exactly one node among many in a distributed cache, thus avoiding the requirement to replicate<br>
or otherwise share data between nodes. A deterministic function is used to locate the node, <em>N'</em>, on which to store<br>
key <em>K</em>:</p>
<pre><code>N' = f(h(K), N1, N2, N3, ... Nm)
</code></pre>
<p>where <em>h(K)</em> is the hash of key <em>K</em>, <em>N1 ... Nm</em> is the set of cache nodes, and <em>N'</em> ∈ <em>N ... Nm</em>.</p>
<p>The function is deterministic in that it consistently produces the same result for a given key and set of cache nodes.<br>
Note that a change in the set of available cache nodes may produce a different target node on which to store the key.</p>
<p>The actual memcached implementation may be supported via one of the following options, expected to be defined in the overlay.</p>
<h2>
<a id="spymemcached" class="anchor" href="#spymemcached" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Spymemcached</h2>
<p>Enable support via the <a href="https://code.google.com/p/spymemcached/">spymemcached library</a>. This is a simple, asynchronous,<br>
single-threaded memcached client that should be the default choice for the majority of deployments.</p>
<p>Support is enabled by including the following dependency in the WAR overlay:</p>
<p>{% include casmodule.html group="org.apereo.cas" module="cas-server-support-memcached-spy" %}</p>
<h2>
<a id="aws-elasticache" class="anchor" href="#aws-elasticache" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>AWS ElastiCache</h2>
<p>You may also use <a href="https://docs.aws.amazon.com/AmazonElastiCache/latest/UserGuide/AutoDiscovery.html">AWS ElastiCache</a><br>
which is a web service that makes it easy to set up, manage, and scale a distributed in-memory<br>
data store or cache environment in the cloud. It provides a high-performance, scalable, and cost-effective caching<br>
solution, while removing the complexity associated with deploying and managing a distributed cache environment.</p>
<p>For clusters running the Memcached engine, ElastiCache supports Auto Discovery—the ability<br>
for client programs to automatically identify all of the nodes in a cache cluster,<br>
and to initiate and maintain connections to all of these nodes. With Auto Discovery,<br>
CAS does not need to manually connect to individual cache nodes; instead, CAS connects to one<br>
Memcached node and retrieves the list of nodes. From that list, CAS is aware of the rest<br>
of the nodes in the cluster and can connect to any of them. You do not need to hard<br>
code the individual cache node endpoints in the configuration</p>
<p>All of the cache nodes in the cluster maintain a list of metadata about all of the other nodes.<br>
This metadata is updated whenever nodes are added or removed from the cluster.</p>
<p>Support is enabled by including the following dependency in the WAR overlay:</p>
<p>{% include casmodule.html group="org.apereo.cas" module="cas-server-support-memcached-aws-elasticache" %}</p>
<h2>
<a id="configuration-considerations" class="anchor" href="#configuration-considerations" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Configuration Considerations</h2>
<p>There are three core configuration concerns with memcached:</p>
<ol>
<li>Hash Algorithm</li>
<li>Node locator strategy</li>
<li>Object serialization mechanism</li>
</ol>
<h3>
<a id="hash-algorithm" class="anchor" href="#hash-algorithm" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Hash Algorithm</h3>
<p>The hash algorithm is used to transform a key value into a memcached storage key that uniquely identifies the<br>
corresponding value. The choice of hashing algorithm has implications for failover behavior that is important<br>
for HA deployments. The <code>FNV1_64_HASH</code> algorithm is recommended since it offers a nice balance of speed and low<br>
collision rate; see the <a href="https://github.com/couchbase/spymemcached/blob/2.8.1/src/main/java/net/spy/memcached/DefaultHashAlgorithm.java">javadocs</a><br>
for alternatives.</p>
<h3>
<a id="node-locator" class="anchor" href="#node-locator" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Node Locator</h3>
<p>The node locator serves as the deterministic node selection function for the memcached client provided by the<br>
underlying spymemcached library. There are two choices:</p>
<ol>
<li><a href="https://github.com/couchbase/spymemcached/blob/2.8.1/src/main/java/net/spy/memcached/ArrayModNodeLocator.java">ARRAY_MOD</a></li>
<li><a href="https://github.com/couchbase/spymemcached/blob/2.9.0/src/main/java/net/spy/memcached/KetamaNodeLocator.java">CONSISTENT</a></li>
</ol>
<p>The array modulus mechanism is the default and suitable for cases when the number of nodes in the memcached pool is<br>
expected to be consistent. The algorithm simply computes an index into the array of memcached nodes:</p>
<pre><code>hash(key) % length(nodes)
</code></pre>
<p>Obviously the selected index is a function of the number of memcached nodes, so variance in number of nodes produces<br>
variance in the node selected to store the key, which is undesirable.</p>
<p>The consistent strategy generally provides a target node that does not vary with the number of nodes. This strategy<br>
should be used in cases where the memcached pool may grow or shrink dynamically, including due to frequent node<br>
failure.</p>
<h3>
<a id="object-serialization" class="anchor" href="#object-serialization" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Object Serialization</h3>
<p>Memcached stores bytes of data, so CAS tickets must be serialized to a byte array prior to storage. CAS ships with<br>
a custom serialization component <code>KryoTranscoder</code> based on the <a href="https://code.google.com/p/kryo/">Kryo</a> serialization<br>
framework. This component is recommended over the default Java serialization mechanism since it produces much more<br>
compact data, which benefits both storage requirements and throughput.</p>
<h2>
<a id="configuration" class="anchor" href="#configuration" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Configuration</h2>
<p>To see the relevant list of CAS properties, please <a href="../configuration/Configuration-Properties.html#memcached-ticket-registry">review this guide</a>.</p>
<h2>
<a id="high-availability-considerations" class="anchor" href="#high-availability-considerations" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>High Availability Considerations</h2>
<p>Memcached does not provide for replication by design, but the client is tolerant to node failures with<br>
<code>failureMode="Redistribute"</code>. In this mode a write failure will simply cause the client to flag the node as failed<br>
and remove it from the set of available nodes. It subsequently recomputes the node location function with the reduced<br>
node set to find a new node on which to store the key. If the node location function selects the same node,<br>
which is likely for the <em>CONSISTENT</em> strategy, a backup node will be computed. The value is written to and read from<br>
the failover node until the primary node recovers. The client will periodically check the failed node for liveliness<br>
and restore it to the node pool as soon as it recovers. When the primary node is resurrected, if it contains a value<br>
for a particular key, it would supersede the value known to the failover node. The most common effect on CAS behavior<br>
in this circumstance would occur when ticket-granting tickets have duplicate values, which could affect single sign-out<br>
and prevent access to services. In particular, services accessed and forced authentications that occur while the<br>
failover service is active would be lost when the failed node recovers. In most cases this behavior is tolerable,<br>
but it can be avoided by restarting the memcached service on the failed node prior to rejoining the cache pool.</p>
<p>A read failure in <em>Redistribute</em> mode causes the node to be removed from the set of available nodes, a failover node<br>
is computed, and a value is read from that node. In most cases this results in a key not found situation. The effect<br>
on CAS behavior depends on the type of ticket requested:</p>
<ul>
<li>Service ticket - Service access would be denied for the requested ticket, but permitted for subsequent attempts since<br>
a new ticket would be generated and validated.</li>
<li>Ticket-granting ticket - The SSO session would be terminated and re-authentication would be required.</li>
</ul>
<p>Read failures are thus entirely innocuous for environments where re-authentication is acceptable.</p>